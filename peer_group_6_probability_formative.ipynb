{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kyrie Irving, the star player for the Mavericks, is making 52% of his three-point shots this season. If he attempts 10 three-pointers in a game, what is the probability distribution of the number of successful shots he makes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'math'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 21\u001b[0m\n\u001b[1;32m     18\u001b[0m k_values \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;241m0\u001b[39m, n \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Calculate Binomial probabilities using the binomial_probability function\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m binomial_probs \u001b[38;5;241m=\u001b[39m [binomial_probability(n, k, p) \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m k_values]\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Print probabilities in a table format\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of Successful 3-Pointers | Probability\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[2], line 14\u001b[0m, in \u001b[0;36mbinomial_probability\u001b[0;34m(n, k, p)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbinomial_probability\u001b[39m(n, k, p):\n\u001b[0;32m---> 14\u001b[0m     comb \u001b[38;5;241m=\u001b[39m combination(n, k)\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m comb \u001b[38;5;241m*\u001b[39m (p \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m k) \u001b[38;5;241m*\u001b[39m ((\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m p) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m (n \u001b[38;5;241m-\u001b[39m k))\n",
      "Cell \u001b[0;32mIn[2], line 10\u001b[0m, in \u001b[0;36mcombination\u001b[0;34m(n, k)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcombination\u001b[39m(n, k):\n\u001b[0;32m---> 10\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mmath\u001b[38;5;241m.\u001b[39mfactorial(n) \u001b[38;5;241m/\u001b[39m (np\u001b[38;5;241m.\u001b[39mmath\u001b[38;5;241m.\u001b[39mfactorial(k) \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mmath\u001b[38;5;241m.\u001b[39mfactorial(n \u001b[38;5;241m-\u001b[39m k))\n",
      "File \u001b[0;32m~/anaconda3/envs/plotEnv/lib/python3.12/site-packages/numpy/__init__.py:414\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    411\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchar\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mchar\u001b[39;00m\n\u001b[1;32m    412\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m char\u001b[38;5;241m.\u001b[39mchararray\n\u001b[0;32m--> 414\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodule \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m has no attribute \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    415\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;18m__name__\u001b[39m, attr))\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'math'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "\n",
    "n = 10  \n",
    "p = 0.52  # Probability of success \n",
    "\n",
    "# Function to calculate combinations (n choose k)\n",
    "def combination(n, k):\n",
    "    return math.factorial(n) / (math.factorial(k) * math.factorial(n - k))\n",
    "\n",
    "#  calculating binomial probability for a specific k\n",
    "def binomial_probability(n, k, p):\n",
    "    comb = combination(n, k)\n",
    "    return comb * (p ** k) * ((1 - p) ** (n - k))\n",
    "\n",
    "# Generating possible values of k (0 to 10 successful shots)\n",
    "k_values = np.arange(0, n + 1)\n",
    "\n",
    "# Calculating Binomial probabilities using the binomial_probability function we defined \n",
    "binomial_probs = [binomial_probability(n, k, p) for k in k_values]\n",
    "\n",
    "# Print probabilities in a table format\n",
    "print(\"Number of Successful 3-Pointers | Probability\")\n",
    "print(\"--------------------------------|------------\")\n",
    "for k, prob in zip(k_values, binomial_probs):\n",
    "    print(f\"{k:^30} | {prob:.4f}\")\n",
    "\n",
    "# Plot the probability distribution\n",
    "plt.bar(k_values, binomial_probs, color='blue', alpha=0.6)\n",
    "plt.xlabel('Number of Successful 3-Pointers')\n",
    "plt.ylabel('Probability')\n",
    "plt.title('Binomial Distribution: Kyrie Irving 3-Point Shooting')\n",
    "plt.xticks(k_values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Q1:How does the distribution you were allocated vary from the other three you were not allocated:\n",
    "\n",
    "1.binomial distribution is discrete(counts success in fixed trials) but normal distribution is continuous, measures things like height , weight\n",
    "\n",
    "2.poisson distribution is counts over time or space for example number of made shots per quarter while binomial deals with a fixed number of trials like 10 shots in our question\n",
    "\n",
    "3.exponential models the time until an event happens for example how long before kyrie makes his first 3 pointer in a game ,while binomial tracks how many success happens in set number of attempts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2:Would the question you chose be used in the context of a different distribution?\n",
    "\n",
    " No, the question we chose, How many 3-pointers does Kyrie make in 10 attempts?, is specific to Binomial and would not be used in other distributions in its current form.\n",
    "The question involves a fixed number of trials (10 attempts) and is looking at successes (made shots) and failures (missed shots). This fits the Binomial Distribution perfectly.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 2: Bayesian Theorem \n",
    "\n",
    "\n",
    "Scenario Explanation:\n",
    "\n",
    "\n",
    "Youâ€™re a doctor, and youâ€™re using a test to determine whether a patient has a rare disease called Disease X. The test has some level of accuracy, but itâ€™s not perfect. Here's the situation:\n",
    "\n",
    "Prior Probability: Before doing the test, you know that 1% of people in the population have Disease X. This is a known fact, so 1% is the prior probability that any random person you test has the disease.\n",
    "\n",
    "Test Accuracy (Likelihood):\n",
    "\n",
    "If a person has the disease, the test is 90% accurate. That means, if they have the disease, the test will correctly say theyâ€™re positive 90% of the time.\n",
    "However, the test is not perfect. If a person doesnâ€™t have the disease, thereâ€™s still a 5% chance that they will test positive (this is the false positive rate).\n",
    "What we Want to Know: If the patient tests positive, whatâ€™s the probability that they actually have the disease?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prior Probability (P(Disease X)): 0.0100\n",
      "Likelihood (P(Pos | Disease X)): 0.9000\n",
      "Evidence (P(Pos)): 0.0585\n",
      "Posterior Probability (P(Disease X | Pos)): 0.1538\n"
     ]
    }
   ],
   "source": [
    "# Given probabilities\n",
    "P_disease = 0.01  # P(Disease X)\n",
    "P_no_disease = 1 - P_disease  # P(No Disease X)\n",
    "P_pos_given_disease = 0.90  # P(Pos | Disease X)\n",
    "P_pos_given_no_disease = 0.05  # P(Pos | No Disease X)\n",
    "\n",
    "# Step 1: Calculate P(Pos) using the law of total probability\n",
    "P_pos = (P_pos_given_disease * P_disease) + (P_pos_given_no_disease * P_no_disease)\n",
    "\n",
    "# Step 2: Apply Bayes' Theorem to calculate P(Disease X | Pos)\n",
    "P_disease_given_pos = (P_pos_given_disease * P_disease) / P_pos\n",
    "\n",
    "# Showing  the results\n",
    "print(f\"Prior Probability (P(Disease X)): {P_disease:.4f}\")\n",
    "print(f\"Likelihood (P(Pos | Disease X)): {P_pos_given_disease:.4f}\")\n",
    "print(f\"Evidence (P(Pos)): {P_pos:.4f}\")\n",
    "print(f\"Posterior Probability (P(Disease X | Pos)): {P_disease_given_pos:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Practical Significance of Bayesian Inference \n",
    "\n",
    "1. Bayesian Inference helps us to not consinder only our beliefs when new data (such as a test result becomes available) thus makes us to put in account the evidences \n",
    "\n",
    "2. In this case, even though the test is 90% accurate, the low prior probability (1% of the population has the disease) means that the chance the person actually has the disease after a positive test result is still only about 15.38%.\n",
    "\n",
    "3. This is important because it tells the doctor that even a positive test result does not necessarily mean the person has the disease. Further testing might be necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 3: Gradient Descent in Code \n",
    "#### Using the participation assignment \"a simple mode\" as reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = np.array([1, 3])\n",
    "y = np.array([3, 6])\n",
    "\n",
    "# Initialize parameters\n",
    "m = -1  \n",
    "b = 1   \n",
    "alpha = 0.1  \n",
    "max_iters = 1000  \n",
    "tolerance = 1e-6  \n",
    "\n",
    "# Store m and b values for visualization\n",
    "m_values = []\n",
    "b_values = []\n",
    "\n",
    "# Gradient Descent Loop\n",
    "for _ in range(max_iters):\n",
    "    # Compute predictions\n",
    "    y_pred = m * x + b\n",
    "    \n",
    "    # Compute gradients\n",
    "    dm = -2 / len(x) * np.sum(x * (y - y_pred))\n",
    "    db = -2 / len(x) * np.sum(y - y_pred)\n",
    "\n",
    "    # Store old values before update for checking convergence\n",
    "    m_old, b_old = m, b\n",
    "\n",
    "    # Update parameters\n",
    "    m -= alpha * dm\n",
    "    b -= alpha * db\n",
    "\n",
    "    # Store new values\n",
    "    m_values.append(m)\n",
    "    b_values.append(b)\n",
    "\n",
    "    # Check convergence condition\n",
    "    if abs(m - m_old) < tolerance and abs(b - b_old) < tolerance:\n",
    "        print(f\"Converged after {_+1} iterations\")\n",
    "        break\n",
    "\n",
    "# Final values of m and b\n",
    "print(f\"Final m: {m}, Final b: {b}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explanation of the Code\n",
    "\n",
    "### Data Initialization\n",
    "- **x = [1,3]**, **y = [3,6]** are the given data points.\n",
    "- **m = -1**, **b = 1** (initial values from the manual calculations).\n",
    "- **Learning rate (Î±) = 0.1**.\n",
    "- **max_iters = 1000** ensures we don't run indefinitely.\n",
    "- **tolerance = 1e-6** is the stopping criterion for small changes in **m** and **b**.\n",
    "\n",
    "### Gradient Descent Loop\n",
    "\n",
    "1. **Predictions are computed:**  \n",
    "   ð‘¦ pred = ð‘š ð‘¥ + ð‘ \n",
    "2. **Gradients are calculated:**\n",
    "\n",
    "   âˆ‚ ð½ âˆ‚ ð‘š = âˆ’ 2 ð‘› âˆ‘ ð‘¥ ð‘– ( ð‘¦ ð‘– âˆ’ ð‘¦ ^ ð‘– ) âˆ‚ ð‘š âˆ‚ ð½ â€‹= âˆ’ ð‘› 2â€‹ âˆ‘ x ð‘–â€‹ ( ð‘¦ ð‘– âˆ’ ð‘¦ ^ ð‘– ) âˆ‚ ð½ âˆ‚ ð‘ = âˆ’ 2 ð‘› âˆ‘ ( ð‘¦ ð‘– âˆ’ ð‘¦ ^ ð‘– ) âˆ‚b âˆ‚J â€‹= âˆ’ n 2 â€‹âˆ‘ ( ð‘¦ ð‘– âˆ’ ð‘¦ ^ ð‘– )\n",
    "\n",
    "3. **Updating Parameters**  \n",
    "   - The new values of **m** and **b** are computed using gradient descent.\n",
    "   - If the changes in **m** and **b** are below the tolerance, the loop stops.\n",
    "\n",
    "### Visualization\n",
    "- **Matplotlib** plots how **m** and **b** change over iterations.\n",
    "\n",
    "### Final Predictions\n",
    "- The final values of **m** and **b** are used to compute predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Key Insights\n",
    "- The **stopping condition** ensures that we don't run unnecessary iterations.\n",
    "- The **learning rate** affects how fast we converge; a too-large value might cause divergence.\n",
    "- **Gradient descent** optimizes **m** and **b** towards reducing error, as seen in the convergence graph."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "plotEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
